---
title: "Exploratory Analysis on Syracuse Data"
output:
html_document: default
html_notebook: default
---


```{r loadLibraries}
library(data.table) 
library(readr)
library(magrittr)
library(lubridate)
library(ggplot2)
library(plyr)
library(ROCR)
library(knitr)
library(hexbin)
library(RColorBrewer)
rf <- colorRampPalette(rev(brewer.pal(11,'Spectral')))
r <- rf(32)
```

```{r readData}
dat <- read_csv("../data/inspections2.csv") %>% data.table()
```

## Examine Variability between inspections and re-inspections

On quick examination, inspector variability appears large. Note that this is 
not necessarily bias, because it could be that inspectors work in better vs. 
worse areas. 

```{r}
dat[ , .(.N,
         mean_critical = mean(`NUM CRITICAL VIOLATIONS (THIS INSPECTION)`),
         sd_critical = sd(`NUM CRITICAL VIOLATIONS (THIS INSPECTION)`),
         mean_nonCritical = mean(`NUM NON-CRITICAL VIOLATIONS (THIS INSPECTION)`),
         sd_nonCritical = sd(`NUM NON-CRITICAL VIOLATIONS (THIS INSPECTION)`)), by = 'INSPECTION TYPE'] %>% 
  kable()

nCritical <- dat[,`NUM CRITICAL VIOLATIONS (THIS INSPECTION)`]
nNonCritical <- dat[,`NUM NON-CRITICAL VIOLATIONS (THIS INSPECTION)`]
inspectionType <- dat[,`INSPECTION TYPE`]

t.test(nCritical[inspectionType=="Inspection"],nCritical[inspectionType=="Re-Inspection"])

ggplot(dat, aes(`INSPECTION TYPE`, `NUM CRITICAL VIOLATIONS (THIS INSPECTION)`)) + 
  geom_boxplot() + labs(title = "Critical Violations by Inspection Type", y = "# Critical Violations", x = "Inspection Type")

t.test(nNonCritical[inspectionType=="Inspection"],nNonCritical[inspectionType=="Re-Inspection"])

ggplot(dat, aes(`INSPECTION TYPE`, `NUM NON-CRITICAL VIOLATIONS (THIS INSPECTION)`)) + 
  geom_boxplot() + labs(title = "Non-Critical Violations by Inspection Type", y = "# Non-Critical Violations", x = "Inspection Type")

```

## Histograms of Number of Violations

```{r}

ggplot(dat, aes(`NUM CRITICAL VIOLATIONS (THIS INSPECTION)`)) + geom_histogram(binwidth = 1, color = "black",fill = "lightblue") + labs(title = "Critical Violations Histogram",x = "Number of Critical Violations",y = "Number of Inspections")

ggplot(dat, aes(`NUM NON-CRITICAL VIOLATIONS (THIS INSPECTION)`)) + geom_histogram(binwidth = 1, color = "black",fill = "lightblue") + labs(title = "Non-Critical Violations Histogram",x = "Number of Non-Critical Violations",y = "Number of Inspections")
```

## Violations by Facility Type 

```{r}
count(dat[,`FACILITY TYPE`])
type = sort(unique(dat[,`FACILITY TYPE`]))
code <- dat[,`FACILITY CODE`]
ind = 0
nType = c()
for (i in type) {
    iThisType <- (dat[,`FACILITY TYPE`]==i)
    ind = ind+1
    nType[ind] <- length(unique(code[iThisType]))
}

ggplot(dat, aes(`FACILITY TYPE`,`NUM CRITICAL VIOLATIONS (THIS INSPECTION)`)) +
  geom_boxplot() + 
  theme(axis.text.x = element_text(angle = 30, hjust = 1)) + 
  labs(title = "Critical Violations by Facility Type",y = "# Critical Violations",x="")

ggplot(dat, aes(`FACILITY TYPE`,`NUM NON-CRITICAL VIOLATIONS (THIS INSPECTION)`)) +
  geom_boxplot() + 
  theme(axis.text.x = element_text(angle = 30, hjust = 1)) + 
  labs(title = "Non-Critical Violations by Facility Type",y = "# Non-Critical Violations",x="")
```


## Are inspections worse for newer restaurants? 

```{r}
ggplot(dat, aes(`DAYS UNTIL PERMIT EXPIRES`)) + geom_histogram(bins = 100, color = "black",fill = "lightblue") + labs(title = "Permit Age at Inspection",x = "Days Until Permit Expires",y = "Number of Inspections") + xlim(0,max(dat[,`DAYS UNTIL PERMIT EXPIRES`]))

hexbinplot(`NUM CRITICAL VIOLATIONS (THIS INSPECTION)`~`DAYS UNTIL PERMIT EXPIRES`,data=dat,colramp=rf,main = "Critical Violations vs. Age of Permit", xlab = "Days Until Permit Expires", ylab = "# Critical Violations",aspect=1,xlim=c(-110,max(dat[,`DAYS UNTIL PERMIT EXPIRES`])))

ds = dat[,`DAYS UNTIL PERMIT EXPIRES`,`NUM NON-CRITICAL VIOLATIONS (THIS INSPECTION)`]
h <- hexbin(ds)
hexbinplot(`NUM NON-CRITICAL VIOLATIONS (THIS INSPECTION)`~`DAYS UNTIL PERMIT EXPIRES`,data=dat,colramp=rf,main = "Non-Critical Violations vs. Age of Permit", xlab = "Days Until Permit Expires", ylab = "# Non-Critical Violations",aspect=1,xlim=c(-110,max(dat[,`DAYS UNTIL PERMIT EXPIRES`])))

```

## Do restaurants get worse inspections if they haven't been inspected in a while? 

```{r}
dat <- dat[!is.na(`NUM CRITICAL VIOLATIONS (PREVIOUS INSPECTION)`)]

ggplot(dat, aes(`DAYS SINCE LAST INSPECTION`)) + geom_histogram(bins = 100, color = "black",fill = "lightblue") + labs(title = "Inspection Frequency",x = "Days Since Last Inspection",y = "Number of Inspections") + xlim(0,max(dat[,`DAYS SINCE LAST INSPECTION`]))

hexbinplot(`NUM CRITICAL VIOLATIONS (THIS INSPECTION)`~`DAYS SINCE LAST INSPECTION`,data=dat,colramp=rf,main = "Critical Violations vs. Last Inspection Date", xlab = "Days Since Last Inspection", ylab = "# Critical Violations",aspect=1)

hexbinplot(`NUM CRITICAL VIOLATIONS (THIS INSPECTION)`~ `NUM CRITICAL VIOLATIONS (PREVIOUS INSPECTION)`,data=dat,colramp=rf,main = "Current and Previous Critical Violations", xlab = "# Critical (Previous)", ylab = "# Critical (Current)",aspect=1)

```

## Quick modeling 

Now we can have an auto-regressive model on previous value. This is also 
known as an AR[1] model. 

```{r}
fit <- glm(`NUM CRITICAL VIOLATIONS (THIS INSPECTION)` ~ `NUM CRITICAL VIOLATIONS (PREVIOUS INSPECTION)`, 
           data = dat, family = "poisson")
summary(fit)
fitted_values <- predict(fit, type = "response")
pred <- prediction(fitted_values, dat_model$num_critical_binary)
plot(performance(pred, "tpr", "fpr"), main="ROC")
performance(pred, measure = "auc")@y.values  # AUC

```

Try a binomial model, but based on histogram above, it doesn't appear that 
a cut-off at 1 critical violation is necessarily the best idea. But it is easier
to look at accuracy at least. 

```{r createBinaryVariables, results = "hide"}
dat[ , num_critical_binary := `NUM CRITICAL VIOLATIONS (THIS INSPECTION)` >= 1]
dat[ , num_critical_previous_binary := `NUM CRITICAL VIOLATIONS (PREVIOUS INSPECTION)` >= 1]

dat_model <- subset(dat, select = c("num_critical_binary", 
                                    "NUM CRITICAL VIOLATIONS (PREVIOUS INSPECTION)"))

dat_model <- dat_model[complete.cases(dat_model)]  # make complete ONLY for quick modelling

fit <- glm(num_critical_binary ~ `NUM CRITICAL VIOLATIONS (PREVIOUS INSPECTION)`,data = dat_model, family = "binomial")

summary(fit)
fitted_values <- predict(fit, type = "response")
pred1 <- prediction(fitted_values, dat_model$num_critical_binary)
plot(performance(pred1, "tpr", "fpr"), main="ROC")
performance(pred1, measure = "auc")@y.values  # AUC
```
```{r logisticModel}
dat_model <- subset(dat, select = c("num_critical_binary", 
                                    "FACILITY TYPE",
                                    "ZIP CODE",
                                    "NUM CRITICAL VIOLATIONS (PREVIOUS INSPECTION)",
                                    "NUM NON-CRITICAL VIOLATIONS (PREVIOUS INSPECTION)",
                                    "DAYS UNTIL PERMIT EXPIRES","DAYS SINCE LAST INSPECTION"))

dat_model <- dat_model[complete.cases(dat_model)]  # make complete ONLY for quick modelling
fit <- glm(num_critical_binary ~ `FACILITY TYPE` + `ZIP CODE` + `NUM CRITICAL VIOLATIONS (PREVIOUS INSPECTION)` + `NUM NON-CRITICAL VIOLATIONS (PREVIOUS INSPECTION)` + `DAYS UNTIL PERMIT EXPIRES` + `DAYS SINCE LAST INSPECTION`,data = dat_model, family = "binomial")

summary(fit)
fitted_values <- predict(fit, type = "response")
pred2 <- prediction(fitted_values, dat_model$num_critical_binary)
plot(performance(pred1, "tpr", "fpr"), main="ROC")
plot(performance(pred2, "tpr", "fpr"), main="ROC",add = TRUE)
performance(pred2, measure = "auc")@y.values  # AUC
```

We should actually be at least this accurate. Though note this is on a 
complete dataset (no NA's). Realistically, we need to impute $t = 1$ values. 

```{r previousAgree}
dat[ , mean(num_critical_binary == num_critical_previous_binary, na.rm = TRUE)]
```

## TODO
- Incorporate features extracted from additional data sets (liquor licenses, crime, census, complains, weather, yelp reviews)
- Try different types of models (ridge regression, random forest, svm)
- Use cross-validation or define a reasonable test set

## Some questions

# Alex's coments all valid
- Do we want to include all facilities, or just restaurants? 
- Is it ok to use previous observations? 
- Should we threshold? If so, where is best place to threshold? 
- Are there violation codes that are predictive of whether the inspections will go poorly the next time?

# Additional Chris comments
- Should we predit on a per-inspection or a per-facility basis? Chicago was per-inspection but I think per-facility makes more sense.
- Merits of cross-validation vs. test set? Setting up a good cross-validation scheme could be difficult. I would propose using one year of data for test.
- This is essentailly a classification problem, so we should use a classifier (svm or random forest)
- 